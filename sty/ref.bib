@article{carpenter2017,
  title = {Stan: {{A Probabilistic Programming Language}}.},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus A. and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  date = {2017},
  journaltitle = {Journal of statistical software},
  shortjournal = {J Stat Softw},
  volume = {76},
  eprint = {36568334},
  eprinttype = {pmid},
  pages = {1},
  location = {United States},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters  conditioned on specified data and constants. As of version 2.14.0, Stan provides  full Bayesian inference for continuous-variable models through Markov chain Monte  Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian  Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using  optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno  algorithm. Stan is also a platform for computing log densities and their  gradients and Hessians, which can be used in alternative algorithms such as  variational Bayes, expectation propagation, and marginal inference using  approximate integration. To this end, Stan is set up so that the densities,  gradients, and Hessians, along with intermediate quantities of the algorithm such  as acceptance probabilities, are easily accessible. Stan can be called from the  command line using the cmdstan package, through R using the rstan package, and  through Python using the pystan package. All three interfaces support sampling  and optimization-based inference with diagnostics and posterior analysis. rstan  and pystan also provide access to log probabilities, gradients, Hessians,  parameter transforms, and specialized plotting.},
  langid = {english},
  pmcid = {PMC9788645},
  keywords = {algorithmic differentiation,Bayesian inference,probabilistic program,Stan}
}

@article{coninx2009,
  title = {Validation of the {{LittlEARS}}® {{Auditory Questionnaire}} in Children with Normal Hearing},
  author = {Coninx, F. and Weichbold, V. and Tsiakpini, L. and Autrique, E. and Bescond, G. and Tamas, L. and Compernol, A. and Georgescu, M. and Koroleva, I. and Le Maner-Idrissi, G. and Liang, W. and Madell, J. and Mikić, B. and Obrycka, A. and Pankowska, A. and Pascu, A. and Popescu, R. and Radulescu, L. and Rauhamäki, T. and Rouev, P. and Kabatova, Z. and Spitzer, J. and family=Thodi, given=Ch., given-i={{Ch}} and Varžic, F. and Vischer, M. and Wang, L. and Zavala, J.S. and Brachmaier, J.},
  date = {2009-12-01},
  journaltitle = {International Journal of Pediatric Otorhinolaryngology},
  shortjournal = {International Journal of Pediatric Otorhinolaryngology},
  volume = {73},
  number = {12},
  pages = {1761--1768},
  issn = {0165-5876},
  doi = {10.1016/j.ijporl.2009.09.036},
  url = {https://www.sciencedirect.com/science/article/pii/S0165587609005230},
  abstract = {Objectives With more children receiving cochlear implants during infancy, there is a need for validated assessments of pre-verbal and early verbal auditory skills. The LittlEARS® Auditory Questionnaire is presented here as the first module of the LittlEARS® test battery. The LittlEARS® Auditory Questionnaire was developed and piloted to assess the auditory behaviour of normal hearing children and hearing impaired children who receive a cochlear implant or hearing aid prior to 24 months of age. This paper presents results from two studies: one validating the LittlEARS® Auditory Questionnaire on children with normal hearing who are German speaking and a second validating the norm curves found after adaptation and administration of the questionnaire to children with normal hearing in 15 different languages. Methods Scores from a group of 218 German and Austrian children with normal hearing between 5 days and 24 months of age were used to create a norm curve. The questionnaire was adapted from the German original into English and then 15 other languages to date. Regression curves were found based on parental responses from 3309 normal hearing infants and toddlers. Curves for each language were compared to the original German validation curve. Results The results of the first study were a norm curve which reflects the age-dependence of auditory behaviour, reliability and homogeneity as a measure of auditory behaviour, and calculations of expected and critical values as a function of age. Results of the second study show that the regression curves found for all the adapted languages are essentially equal to the German norm curve, as no statistically significant differences were found. Conclusions The LittlEARS® Auditory Questionnaire is a valid, language-independent tool for assessing the early auditory behaviour of infants and toddlers with normal hearing. The results of this study suggest that the LittlEARS® Auditory Questionnaire could also be very useful for documenting children's progress with their current amplification, providing evidence of the need for implantation, or highlighting the need for follow-up in other developmental areas.},
  keywords = {Auditory behaviours,Auditory development,Cochlear implant,Early implantation,Infants and toddlers,LittlEARS Auditory Questionnaire}
}

@article{haertel1989,
  title = {Using {{Restricted Latent Class Models}} to {{Map}} the {{Skill Structure}} of {{Achievement Items}}},
  author = {Haertel, Edward H.},
  date = {1989-12-01},
  journaltitle = {Journal of Educational Measurement},
  shortjournal = {Journal of Educational Measurement},
  volume = {26},
  number = {4},
  pages = {301--321},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {0022-0655},
  doi = {10.1111/j.1745-3984.1989.tb00336.x},
  url = {https://doi.org/10.1111/j.1745-3984.1989.tb00336.x},
  urldate = {2024-10-22},
  abstract = {This paper presents a new method for using certain restricted latent class models, referred to as binary skills models, to determine the skills required by a set o f test items. The method is applied to reading achievement data from a nationally representative sample o f fourth-grade students and offers useful perspectives on test structure and examinee ability, distinct from those provided by other methods o f analysis. Models fitted to small, overlapping sets o f items are integrated into a common skill map, and the nature o f each skill is then inferred from the characteristics o f the items for which it is required. The reading comprehension items examined conform closely to a unidimensional scale with six discrete skill levels that range from an inability to comprehend or match isolated words in a reading passage to the abilities required to integrate passage content with general knowledge and to recognize the main ideas o f the most difficult passages on the test.}
}

@article{junker2001,
  title = {Cognitive {{Assessment Models}} with {{Few Assumptions}}, and {{Connections}} with {{Nonparametric Item Response Theory}}},
  author = {Junker, Brian W. and Sijtsma, Klaas},
  date = {2001-09-01},
  journaltitle = {Applied Psychological Measurement},
  volume = {25},
  number = {3},
  pages = {258--272},
  publisher = {SAGE Publications Inc},
  issn = {0146-6216},
  doi = {10.1177/01466210122032064},
  url = {https://doi.org/10.1177/01466210122032064},
  urldate = {2024-10-22},
  abstract = {Some usability and interpretability issues for single-strategy cognitive assessment models are considered. These models posit a stochastic conjunctive relationship between a set of cognitive attributes to be assessed and performance on particular items/tasks in the assessment. The models considered make few assumptions about the relationship between latent attributes and task performance beyond a simple conjunctive structure. An example shows that these models can be sensitive to cognitive attributes, even in data designed to well fit the Rasch model. Several stochastic ordering and monotonicity properties are considered that enhance the interpretability of the models. Simple data summaries are identified that inform about the presence or absence of cognitive attributes when the full computational power needed to estimate the models is not available.}
}

@book{rupp2010,
  title = {Diagnostic Measurement: {{Theory}}, Methods, and Applications.},
  author = {Rupp, André A. and Templin, Jonathan and Henson, Robert A.},
  date = {2010},
  series = {Diagnostic Measurement: {{Theory}}, Methods, and Applications.},
  publisher = {Guilford Press},
  location = {New York,  NY,  US},
  abstract = {This book provides a comprehensive introduction to the theory and practice of diagnostic classification models (DCMs), which are useful for statistically driven diagnostic decision making. DCMs can be employed in a wide range of disciplines, including educational assessment and clinical psychology. For the first time in a single volume, the authors present the key conceptual underpinnings and methodological foundations for applying these models in practice. Specifically, they discuss a unified approach to DCMs, the mathematical structure of DCMs and their relationship to other latent variable models, and the implementation and estimation of DCMs using Mplus. The book's highly accessible language, real-world applications, numerous examples, and clearly annotated equations will encourage professionals and students to explore the utility and statistical properties of DCMs in their own projects. The companion website (projects.coe.uga.edu/dcm) features data sets, Mplus syntax code, and output. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-1-60623-527-0},
  pagetotal = {348},
  keywords = {*Decision Making,*Psychodiagnosis,*Psychodiagnostic Typologies,*Statistical Analysis,Models}
}

@article{wachtlin2017,
  title = {Development and Evaluation of the {{LittlEARS}}® {{Early Speech Production Questionnaire}} – {{LEESPQ}}},
  author = {Wachtlin, Bianka and Brachmaier, Joanna and Amann, Edda and Hoffmann, Vanessa and Keilmann, Annerose},
  date = {2017-03-01},
  journaltitle = {International Journal of Pediatric Otorhinolaryngology},
  shortjournal = {International Journal of Pediatric Otorhinolaryngology},
  volume = {94},
  pages = {23--29},
  issn = {0165-5876},
  doi = {10.1016/j.ijporl.2017.01.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0165587617300083},
  abstract = {Objective Universal Newborn Hearing Screening programs, now instituted throughout the German-speaking countries, allow hearing loss to be detected and treated much earlier than ever before. With this earlier detection, arises the need for tools fit for assessing the very early speech and language production development of today's younger (0–18 month old) children. We have created the LittlEARS® Early Speech Production Questionnaire, with the aim of meeting this need. Methods 600 questionnaires of the pilot version of the LittlEARS® Early Speech Production Questionnaire were distributed to parents via pediatricians' practices, day care centers, and personal contact. The completed questionnaires were statistically analyzed to determine their reliability, predictive accuracy, internal consistency, and to what extent gender or unilingualism influenced a child's score. Further, a norm curve was generated to plot the children's increased expected speech production ability with age. Results Analysis of the data from the 352/600 returned questionnaires revealed that scores on LittlEARS® Early Speech Production Questionnaire correlate positively with a child's age, with older children scoring higher than do younger children. Further, the questionnaire has a high measuring reliability, high predictability, high unidemensionality of scale, and is not significantly gender or uni-/multilingually biased. A norm curve for expected development with age was created. Conclusions The LittlEARS® Early Speech Production Questionnaire (LEESPQ) is a valid tool for assessing the most important milestones in very early development of speech and language production of German language children with normal hearing aged 0–18 months old. The questionnaire is a potentially useful tool for long-term infant screening and follow-up testing and for children with normal hearing and those who would benefit from or use hearing devices.},
  keywords = {Early speech and language production,Infant vocalization,Language development,LEESPQ,Prelexical vocalization,Speech development}
}
